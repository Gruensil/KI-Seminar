{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gruensil/KI-Seminar/blob/main/tutorials/Open_Source_LLMs_Getting_Started.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIklqAGp5jGG"
      },
      "source": [
        "#  Open Source LLMs: Getting Started\n",
        "\n",
        "### Goal: Start generating text in the next 120 seconds\n",
        "\n",
        "**By: Glenn Parham, [Defense Digital Service](https://dds.mil)**\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/deptofdefense/LLMs-at-DoD/blob/main/tutorials/Open_Source_LLMs_Getting_Started.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4i3b1N9555u"
      },
      "source": [
        "## Getting Started\n",
        "\n",
        "In this colab notebook, we'll want to use a **T4** GPU (A100/V100 will also work).  You may switch to this by going to \"Runtime\" then \"Change Runtime Type\"\n",
        "\n",
        "This accelerated GPU will ensure inference of LLMs will not take forever."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IgWY91D6xLb"
      },
      "source": [
        "Let's verify you're using a T4.  Once you run this cell, you should get the following output (if you're not, skip this cell):![Screenshot 2023-10-10 at 2.48.51 PM.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtQrVBJ66iI4",
        "outputId": "3627dd46-bec9-4d07-c2f3-3a1c1796b461"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-ea88581e-d522-243e-f683-d7fe7b003f92)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcMGU3RN9XF1"
      },
      "source": [
        "To get around annoying text-wrapping issues, run this cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fUM2MOqI0LgU"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YW7zaggg7Br9"
      },
      "source": [
        "## Installing Dependencies\n",
        "\n",
        "You'll need to install the following requirements\n",
        "\n",
        "Python Libraries\n",
        "- HuggingFace\n",
        "- Llama-cpp-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XvwWBzDEiLJq",
        "outputId": "6f12759f-f818-41e0-9c69-84082ec1277e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.3.7.tar.gz (66.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.7/66.7 MB\u001b[0m \u001b[31m231.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting typing-extensions>=4.5.0 (from llama-cpp-python)\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting numpy>=1.20.0 (from llama-cpp-python)\n",
            "  Downloading numpy-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m148.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting jinja2>=2.11.3 (from llama-cpp-python)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2>=2.11.3->llama-cpp-python)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m168.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m192.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m175.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.7-cp311-cp311-linux_x86_64.whl size=4601137 sha256=85106838512c782c0230cca54efb28c560ac0220222a88066bb426c5758a5c2b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rgkp8pb2/wheels/eb/82/79/ac77fcd49324b75ae6aa18e63a87cf9da4371a57e2cdc8dc03\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: typing-extensions, numpy, MarkupSafe, diskcache, jinja2, llama-cpp-python\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.5\n",
            "    Uninstalling Jinja2-3.1.5:\n",
            "      Successfully uninstalled Jinja2-3.1.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "diffusers 0.32.2 requires huggingface-hub>=0.23.2, but you have huggingface-hub 0.17.1 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "transformers 4.48.3 requires huggingface-hub<1.0,>=0.24.0, but you have huggingface-hub 0.17.1 which is incompatible.\n",
            "langchain 0.3.19 requires numpy<2,>=1.26.4; python_version < \"3.12\", but you have numpy 2.2.3 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.3 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.2.3 which is incompatible.\n",
            "sentence-transformers 3.4.1 requires huggingface-hub>=0.20.0, but you have huggingface-hub 0.17.1 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.3 which is incompatible.\n",
            "accelerate 1.3.0 requires huggingface-hub>=0.21.0, but you have huggingface-hub 0.17.1 which is incompatible.\n",
            "peft 0.14.0 requires huggingface-hub>=0.25.0, but you have huggingface-hub 0.17.1 which is incompatible.\n",
            "pytensor 2.27.1 requires numpy<2,>=1.17.0, but you have numpy 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 diskcache-5.6.3 jinja2-3.1.6 llama-cpp-python-0.3.7 numpy-2.2.3 typing-extensions-4.12.2\n"
          ]
        }
      ],
      "source": [
        "## INSTALLING HUGGINGFACE\n",
        "!pip install huggingface-hub -q\n",
        "\n",
        "## INSTALLING llama-cpp-python\n",
        "# GPU llama-cpp-python; Starting from version llama-cpp-python==0.1.79, it supports GGUF\n",
        "!pip install llama-cpp-python --force-reinstall --upgrade --no-cache-dir\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhVkaTkn76eY"
      },
      "source": [
        "Next, you'll need to download the model weights from HuggingFace.\n",
        "\n",
        "Here's a list of models you can choose from: https://huggingface.co/models?pipeline_tag=text-generation&sort=trending&search=GGUF\n",
        "\n",
        "Note: The model you select **must** be of type \"GGUF\"\n",
        "\n",
        "GGUF is...\n",
        "- binary file format for storing models for inference\n",
        "- designed for fast loading and saving of models\n",
        "- easy to use (with a few lines of code)\n",
        "- mmap (memory mapping) compatibility: models can be loaded using mmap for fast loading and saving."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "OduLhLRQaZiF",
        "outputId": "28b6d06a-e5b1-48e5-b76a-641e7ace1ac8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title Select Large Language Model\n",
        "selected_llm = 'Mistral-7B-OpenOrca' # @param [\"Mistral-7B\", \"Mistral-7B-OpenOrca\", \"Llama-2-13B-Chat\"]\n",
        "\n",
        "model_dic = {\"Mistral-7B\":{\"HF_REPO_NAME\":\"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\",\"HF_MODEL_NAME\":\"mistral-7b-instruct-v0.1.Q4_K_M.gguf\"},\n",
        "           \"Mistral-7B-OpenOrca\":{\"HF_REPO_NAME\":\"TheBloke/Mistral-7B-OpenOrca-GGUF\",\"HF_MODEL_NAME\":\"mistral-7b-openorca.Q5_K_M.gguf\"},\n",
        "             \"Llama-2-13B-Chat\":{\"HF_REPO_NAME\":\"TheBloke/Llama-2-13B-chat-GGUF\",\"HF_MODEL_NAME\":\"llama-2-13b-chat.Q4_K_S.gguf\"}\n",
        "             }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "bafeb9c240a94cd7b5ee9f80733d2573",
            "e85564bafcf54555b7894545c57cdfde",
            "46b555f8a4ec477f847a077a9d676010",
            "f8f4588ab3ca4beaa0d0ce33e07f6479",
            "9876f0de60e84c98b1d6cdec34e65cf3",
            "f22f2717e50d43609e33d28ada038996",
            "54e3290ded94495a92d0bd4d2811a61b",
            "a465ef7afc644358a4b1aeb8164ada5a",
            "8ab3ff7ef9fb49f9be11791c13542a4f",
            "fbaca0df200845c3906c9bab101d7a0c",
            "0542563a92f24b95b760580da5f5bb55"
          ]
        },
        "id": "SQPrsqWZkv97",
        "outputId": "377a1d8e-13e6-4526-b0ed-8ac006431ec2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)openorca.Q5_K_M.gguf:   0%|          | 0.00/5.13G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bafeb9c240a94cd7b5ee9f80733d2573"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "\n",
        "HF_REPO_NAME = model_dic[selected_llm]['HF_REPO_NAME']\n",
        "HF_MODEL_NAME = model_dic[selected_llm]['HF_MODEL_NAME']\n",
        "LOCAL_DIR_NAME = \"models\"\n",
        "\n",
        "os.makedirs(LOCAL_DIR_NAME, exist_ok=True)\n",
        "model_path = hf_hub_download(\n",
        "    repo_id=HF_REPO_NAME, filename=HF_MODEL_NAME, local_dir=LOCAL_DIR_NAME\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RB46-5Aj8lsk"
      },
      "source": [
        "Now, let's initialize the \"Llama\" framework.\n",
        "\n",
        "So this is a bit messy.  Llama-cpp was named after Meta's open-source \"*Llama*\" LLMs.  The framework was built to make it easy to locally run & program with this LLM.  However, now, the framework as been abstracted and modified to work with ***any*** open-source text-generation LLM, as long as it is in the GGUF model file type.\n",
        "\n",
        "In our case, we are using the Mistral open-source LLM and Llama-cpp as our framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ey4WSCjxqb_X",
        "outputId": "6705d5a2-b35f-43d0-8455-780525623181"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from models/mistral-7b-openorca.Q5_K_M.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = open-orca_mistral-7b-openorca\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 17\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32002]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32002]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32002]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q5_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "print_info: file format = GGUF V2\n",
            "print_info: file type   = Q5_K - Medium\n",
            "print_info: file size   = 4.78 GiB (5.67 BPW) \n",
            "init_tokenizer: initializing tokenizer for type 1\n",
            "load: control token:      2 '</s>' is not marked as EOG\n",
            "load: control token:      1 '<s>' is not marked as EOG\n",
            "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
            "load: special tokens cache size = 5\n",
            "load: token to piece cache size = 0.1637 MB\n",
            "print_info: arch             = llama\n",
            "print_info: vocab_only       = 0\n",
            "print_info: n_ctx_train      = 32768\n",
            "print_info: n_embd           = 4096\n",
            "print_info: n_layer          = 32\n",
            "print_info: n_head           = 32\n",
            "print_info: n_head_kv        = 8\n",
            "print_info: n_rot            = 128\n",
            "print_info: n_swa            = 0\n",
            "print_info: n_embd_head_k    = 128\n",
            "print_info: n_embd_head_v    = 128\n",
            "print_info: n_gqa            = 4\n",
            "print_info: n_embd_k_gqa     = 1024\n",
            "print_info: n_embd_v_gqa     = 1024\n",
            "print_info: f_norm_eps       = 0.0e+00\n",
            "print_info: f_norm_rms_eps   = 1.0e-05\n",
            "print_info: f_clamp_kqv      = 0.0e+00\n",
            "print_info: f_max_alibi_bias = 0.0e+00\n",
            "print_info: f_logit_scale    = 0.0e+00\n",
            "print_info: n_ff             = 14336\n",
            "print_info: n_expert         = 0\n",
            "print_info: n_expert_used    = 0\n",
            "print_info: causal attn      = 1\n",
            "print_info: pooling type     = 0\n",
            "print_info: rope type        = 0\n",
            "print_info: rope scaling     = linear\n",
            "print_info: freq_base_train  = 10000.0\n",
            "print_info: freq_scale_train = 1\n",
            "print_info: n_ctx_orig_yarn  = 32768\n",
            "print_info: rope_finetuned   = unknown\n",
            "print_info: ssm_d_conv       = 0\n",
            "print_info: ssm_d_inner      = 0\n",
            "print_info: ssm_d_state      = 0\n",
            "print_info: ssm_dt_rank      = 0\n",
            "print_info: ssm_dt_b_c_rms   = 0\n",
            "print_info: model type       = 7B\n",
            "print_info: model params     = 7.24 B\n",
            "print_info: general.name     = open-orca_mistral-7b-openorca\n",
            "print_info: vocab type       = SPM\n",
            "print_info: n_vocab          = 32002\n",
            "print_info: n_merges         = 0\n",
            "print_info: BOS token        = 1 '<s>'\n",
            "print_info: EOS token        = 32000 '<dummy32000>'\n",
            "print_info: UNK token        = 0 '<unk>'\n",
            "print_info: LF token         = 13 '<0x0A>'\n",
            "print_info: EOG token        = 32000 '<dummy32000>'\n",
            "print_info: max token length = 48\n",
            "load_tensors: layer   0 assigned to device CPU\n",
            "load_tensors: layer   1 assigned to device CPU\n",
            "load_tensors: layer   2 assigned to device CPU\n",
            "load_tensors: layer   3 assigned to device CPU\n",
            "load_tensors: layer   4 assigned to device CPU\n",
            "load_tensors: layer   5 assigned to device CPU\n",
            "load_tensors: layer   6 assigned to device CPU\n",
            "load_tensors: layer   7 assigned to device CPU\n",
            "load_tensors: layer   8 assigned to device CPU\n",
            "load_tensors: layer   9 assigned to device CPU\n",
            "load_tensors: layer  10 assigned to device CPU\n",
            "load_tensors: layer  11 assigned to device CPU\n",
            "load_tensors: layer  12 assigned to device CPU\n",
            "load_tensors: layer  13 assigned to device CPU\n",
            "load_tensors: layer  14 assigned to device CPU\n",
            "load_tensors: layer  15 assigned to device CPU\n",
            "load_tensors: layer  16 assigned to device CPU\n",
            "load_tensors: layer  17 assigned to device CPU\n",
            "load_tensors: layer  18 assigned to device CPU\n",
            "load_tensors: layer  19 assigned to device CPU\n",
            "load_tensors: layer  20 assigned to device CPU\n",
            "load_tensors: layer  21 assigned to device CPU\n",
            "load_tensors: layer  22 assigned to device CPU\n",
            "load_tensors: layer  23 assigned to device CPU\n",
            "load_tensors: layer  24 assigned to device CPU\n",
            "load_tensors: layer  25 assigned to device CPU\n",
            "load_tensors: layer  26 assigned to device CPU\n",
            "load_tensors: layer  27 assigned to device CPU\n",
            "load_tensors: layer  28 assigned to device CPU\n",
            "load_tensors: layer  29 assigned to device CPU\n",
            "load_tensors: layer  30 assigned to device CPU\n",
            "load_tensors: layer  31 assigned to device CPU\n",
            "load_tensors: layer  32 assigned to device CPU\n",
            "load_tensors: tensor 'token_embd.weight' (q5_K) (and 290 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
            "load_tensors:   CPU_Mapped model buffer size =  4893.00 MiB\n",
            "llama_init_from_model: n_seq_max     = 1\n",
            "llama_init_from_model: n_ctx         = 4096\n",
            "llama_init_from_model: n_ctx_per_seq = 4096\n",
            "llama_init_from_model: n_batch       = 512\n",
            "llama_init_from_model: n_ubatch      = 512\n",
            "llama_init_from_model: flash_attn    = 0\n",
            "llama_init_from_model: freq_base     = 10000.0\n",
            "llama_init_from_model: freq_scale    = 1\n",
            "llama_init_from_model: n_ctx_per_seq (4096) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
            "llama_kv_cache_init: kv_size = 4096, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1\n",
            "llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 28: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 29: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 30: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 31: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init:        CPU KV buffer size =   512.00 MiB\n",
            "llama_init_from_model: KV self size  =  512.00 MiB, K (f16):  256.00 MiB, V (f16):  256.00 MiB\n",
            "llama_init_from_model:        CPU  output buffer size =     0.12 MiB\n",
            "llama_init_from_model:        CPU compute buffer size =   296.01 MiB\n",
            "llama_init_from_model: graph nodes  = 1030\n",
            "llama_init_from_model: graph splits = 1\n",
            "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | AVX512 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '32000', 'general.architecture': 'llama', 'llama.rope.freq_base': '10000.000000', 'llama.context_length': '32768', 'general.name': 'open-orca_mistral-7b-openorca', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '17'}\n",
            "Using fallback chat format: llama-2\n"
          ]
        }
      ],
      "source": [
        "from llama_cpp import Llama\n",
        "\n",
        "llm = Llama(\n",
        "    model_path=model_path,\n",
        "    n_threads=2, # CPU cores\n",
        "    n_batch=512, # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
        "    n_gpu_layers=30, # The max for this model is 30 in a T4, If you use llama 2 70B, you'll need to put fewer layers on the GPU\n",
        "    n_ctx=4096, # Context window\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXHZz82oZcbJ"
      },
      "source": [
        "# The Fun Part\n",
        "\n",
        "You're all ready to actually use this LLM!  Feel free to change the prompt variable to whatever you'd like.  Once you run the cell, it'll begin to stream the generated text.  The speed will depend on the GPU you selected (T4 vs. V100)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "5pWRfNKHkKNX",
        "outputId": "65650787-6d82-4446-8c44-a9db03c66854"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt = \"\"\"\n",
        "What is the US Department of Defense?\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "I4vmXyiCrg_z",
        "outputId": "8052fe54-4eb8-480b-d3e6-6ba1fdffa4f2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The US Department of Defense (DoD) is the federal executive department responsible for coordinating and supervising all agencies and functions concerned with national security and the armed forces of the United States. The DoD was established on July 26, 1947, as a response to the need for a unified and effective defense establishment following World War II. The department is headed by the Secretary of Defense, who is a member of the president's Cabinet."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    5441.41 ms\n",
            "llama_perf_context_print: prompt eval time =    5441.20 ms /    12 tokens (  453.43 ms per token,     2.21 tokens per second)\n",
            "llama_perf_context_print:        eval time =   63385.81 ms /    98 runs   (  646.79 ms per token,     1.55 tokens per second)\n",
            "llama_perf_context_print:       total time =   68943.54 ms /   110 tokens\n"
          ]
        }
      ],
      "source": [
        "response = llm(prompt,stream=True,stop=[\"\\n\\n\"],temperature=0, max_tokens=200)\n",
        "generated_text = \"\"\n",
        "for output in response:\n",
        "    result = output['choices'][0]['text']\n",
        "    generated_text+=result\n",
        "    print(result,end=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generiere_arztbrief(name, diagnose, behandlung):\n",
        "    # Erstelle einen Prompt, der die Patientendaten strukturiert zusammenführt\n",
        "    prompt = (\n",
        "        f\"Patient: {name}.\\n\"\n",
        "        f\"Diagnose: {diagnose}.\\n\"\n",
        "        f\"Behandlungsansatz: {behandlung}.\\n\\n\"\n",
        "        \"Schreibe einen ausführlichen, professionellen Arztbrief, der die folgenden Informationen beinhaltet:\"\n",
        "        \"\\n- Patientendaten\\n- Diagnose\\n- Behandlungsplan und Empfehlungen\\n- Weitere Anmerkungen\\n\\n\"\n",
        "        \"Arztbrief:\"\n",
        "    )\n",
        "\n",
        "    # Generiere den Arztbrief mit dem LLM\n",
        "    response = llm(prompt,stream=True,stop=[\"\\n\\n\"],temperature=0, max_tokens=200)\n",
        "    generated_text = \"\"\n",
        "    for output in response:\n",
        "        result = output['choices'][0]['text']\n",
        "        generated_text+=result\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "UxdkjiNQkGxq",
        "outputId": "f0a639fe-c8a6-4b48-cadc-d411cb54d6ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Willkommen zum Arztbrief-Generator!\")\n",
        "print(\"Bitte gib die folgenden Daten ein:\")\n",
        "\n",
        "patientenname = input(\"Patientenname: \")\n",
        "diagnose = input(\"Diagnose: \")\n",
        "behandlung = input(\"Behandlungsansatz: \")\n",
        "\n",
        "brief = generiere_arztbrief(patientenname, diagnose, behandlung)\n",
        "print(\"\\n----- Automatisch generierter Arztbrief -----\\n\")\n",
        "print(brief)"
      ],
      "metadata": {
        "id": "o_QEgOlnkMST",
        "outputId": "d3884e7d-1303-4af9-b132-42d6cb855ad7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Willkommen zum Arztbrief-Generator!\n",
            "Bitte gib die folgenden Daten ein:\n",
            "Patientenname: Max Mustermann\n",
            "Diagnose: aktue Bronchitits\n",
            "Behandlungsansatz: Empfehlung zur Schonung und symptomatischer Behandlung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 1 prefix-match hit, remaining 110 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    5441.41 ms\n",
            "llama_perf_context_print: prompt eval time =  191429.66 ms /   219 tokens (  874.11 ms per token,     1.14 tokens per second)\n",
            "llama_perf_context_print:        eval time =     607.28 ms /     1 runs   (  607.28 ms per token,     1.65 tokens per second)\n",
            "llama_perf_context_print:       total time =   53736.15 ms /   220 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----- Automatisch generierter Arztbrief -----\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bafeb9c240a94cd7b5ee9f80733d2573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e85564bafcf54555b7894545c57cdfde",
              "IPY_MODEL_46b555f8a4ec477f847a077a9d676010",
              "IPY_MODEL_f8f4588ab3ca4beaa0d0ce33e07f6479"
            ],
            "layout": "IPY_MODEL_9876f0de60e84c98b1d6cdec34e65cf3"
          }
        },
        "e85564bafcf54555b7894545c57cdfde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f22f2717e50d43609e33d28ada038996",
            "placeholder": "​",
            "style": "IPY_MODEL_54e3290ded94495a92d0bd4d2811a61b",
            "value": "Downloading (…)openorca.Q5_K_M.gguf: 100%"
          }
        },
        "46b555f8a4ec477f847a077a9d676010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a465ef7afc644358a4b1aeb8164ada5a",
            "max": 5131421440,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ab3ff7ef9fb49f9be11791c13542a4f",
            "value": 5131421440
          }
        },
        "f8f4588ab3ca4beaa0d0ce33e07f6479": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbaca0df200845c3906c9bab101d7a0c",
            "placeholder": "​",
            "style": "IPY_MODEL_0542563a92f24b95b760580da5f5bb55",
            "value": " 5.13G/5.13G [00:31&lt;00:00, 208MB/s]"
          }
        },
        "9876f0de60e84c98b1d6cdec34e65cf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f22f2717e50d43609e33d28ada038996": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54e3290ded94495a92d0bd4d2811a61b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a465ef7afc644358a4b1aeb8164ada5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ab3ff7ef9fb49f9be11791c13542a4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fbaca0df200845c3906c9bab101d7a0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0542563a92f24b95b760580da5f5bb55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}